# -*- coding: utf-8 -*-
"""Tarea 2-IA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MWHlNVX1ouY7_u4pr7akbFARxkGSuDnW

# Universidad de O'Higgins

## Escuela de Ingeniería
## COM4402: Introducción a Inteligencia Artificial

### **Tarea 2: Clasificación de Dígitos Manuscritos con Redes Neuronales**

### Estudiante: Matías González

El objetivo de esta tarea es utilizar redes neuronales en un problema de clasificación de dígitos. Se utilizará el conjunto de datos Optical Recognition of Handwritten Digits Data Set. Este conjunto tiene 64 características, con 10 clases y 5620 muestras en total. La base de datos estará disponible en U-Campus.

Las redes a ser entrenadas tienen la siguiente estructura: capa de entrada de dimensionalidad 64 (correspondiente a los datos de entrada), capas ocultas (una o dos) y capa de salida con 10 neuronas y función de activación softmax. La función de loss (pérdida) es entropía cruzada. El optimizador que se
debe usar es Adam. La función softmax está implícita al usar la función de pérdida CrossEntropyLoss de PyTorch (**no se debe agregar softmax a la salida de la red**).

Se usará PyTorch para entrenar y validar la red neuronal que implementa el clasificador de dígitos. Se analizará los efectos de cambiar el tamaño de la red (número de capas ocultas y de neuronas en estas
capas) y la función de activación.

El siguiente código base debe ser usado para realizar las actividades pedidas.

## Observación: Antes de ejecutar su código, active el uso de GPU en Google Colab para acelerar el proceso de entrenamiento.

### Para esto: vaya a "Entorno de Ejecución" en el menú superior, haga click en "Cambiar tipo de entorno de ejecución", y seleccionar/verificar "GPU" en "Acelerador de Hardware"
"""

import pandas as pd
import torch
import torch.nn as nn
import numpy as np
import time
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

"""## Subir datasets de dígitos (train)"""

!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_train.txt
!wget https://raw.githubusercontent.com/Felipe1401/Mineria/main/dataset_digits/1_digits_test.txt

"""## Leer dataset de dígitos"""

column_names = ["feat" + str(i) for i in range(64)]
column_names.append("class")

df_train_val = pd.read_csv('1_digits_train.txt', names = column_names)
df_train_val

df_test = pd.read_csv('1_digits_test.txt', names = column_names)
df_test

df_train, df_val = train_test_split(df_train_val, test_size = 0.3, random_state = 10)

scaler = StandardScaler().fit(df_train.iloc[:,0:64])
df_train.iloc[:,0:64] = scaler.transform(df_train.iloc[:,0:64])
df_val.iloc[:,0:64] = scaler.transform(df_val.iloc[:,0:64])
df_test.iloc[:,0:64] = scaler.transform(df_test.iloc[:,0:64])

df_train

"""## Crear datasets y dataloaders para pytorch (train)"""

# Crear datasets
feats_train = df_train.to_numpy()[:,0:64].astype(np.float32)
labels_train = df_train.to_numpy()[:,64].astype(int)
dataset_train = [ {"features":feats_train[i,:], "labels":labels_train[i]} for i in range(feats_train.shape[0]) ]

feats_val = df_val.to_numpy()[:,0:64].astype(np.float32)
labels_val = df_val.to_numpy()[:,64].astype(int)
dataset_val = [ {"features":feats_val[i,:], "labels":labels_val[i]} for i in range(feats_val.shape[0]) ]

feats_test = df_test.to_numpy()[:,0:64].astype(np.float32)
labels_test = df_test.to_numpy()[:,64].astype(int)
dataset_test = [ {"features":feats_test[i,:], "labels":labels_test[i]} for i in range(feats_test.shape[0]) ]

# Crear dataloaders
dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0)
dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=128, shuffle=True, num_workers=0)
dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=128, shuffle=True, num_workers=0)

"""## Crear modelos y aplicar los entrenamientos por defecto (Sin criterio de Parada)

Mejor red en la validación
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import time

total_train_perdida=[]
total_val_perdida=[]
accuracy=[]
#Creación de modelos.
nombre_modelos=[]
def modelos(numero_modelo):
    if numero_modelo== 1:
        nombre_modelos.append('a')
        return nn.Sequential(
            nn.Linear(64, 10),
            nn.ReLU(),
            nn.Linear(10, 10)
        )
    elif numero_modelo == 2:
        nombre_modelos.append('b')
        return nn.Sequential(
            nn.Linear(64, 40),
            nn.ReLU(),
            nn.Linear(40, 10)
        )
    elif numero_modelo == 3:
        nombre_modelos.append('c')
        return nn.Sequential(
            nn.Linear(64, 10),
            nn.Tanh(),
            nn.Linear(10, 10)
        )
    elif numero_modelo == 4:
        nombre_modelos.append('d')
        return nn.Sequential(
            nn.Linear(64, 40),
            nn.Tanh(),
            nn.Linear(40, 10)
        )
    elif numero_modelo == 5:
        nombre_modelos.append('e')
        return nn.Sequential(
            nn.Linear(64, 10),
            nn.ReLU(),
            nn.Linear(10, 10),
            nn.ReLU(),
            nn.Linear(10, 10)
        )
    elif numero_modelo == 6:
        nombre_modelos.append('f')
        return nn.Sequential(
            nn.Linear(64, 40),
            nn.ReLU(),
            nn.Linear(40, 40),
            nn.ReLU(),
            nn.Linear(40, 10)
        )

#Se recorre cada modelo.
for n_red in range(1,7):
 print(n_red)
 model = modelos(n_red)
 start = time.time()

 #Aseguro que se utilice la GPU.
 device = torch.device('cuda')
 model = model.to(device)
 #Se define la función de pérdida.
 criterion = nn.CrossEntropyLoss()
 #Se define un optimizador.
 optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

 #Se guarda en lista, las perdidas de entrenamiento y validación.
 perdida_entrenamiento = []
 perdida_validacion = []

 epochs = []
 # Entrenamiento de la red por n epocas
 for epoch in range(250):

   # Guardar loss de cada batch
   perdida_entrenamiento_batches = []
   perdida_validacion_batches = []

################################################################################
#-------------------------------Entrenamiento ---------------------------------#
################################################################################
   model.train()   #Comienza el entrenamiento.

   # Debemos recorrer cada batch (lote de los datos)
   for i, data in enumerate(dataloader_train, 0):
    # Procesar batch actual
    inputs = data["features"].to(device) # Características
    labels = data["labels"].to(device)   # Clases
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = model(inputs)           # Predicciones
    loss = criterion(outputs, labels) # Loss de entrenamiento
    loss.backward()                   # Backpropagation
    optimizer.step()

    # Se guarda la pérdida de entrenamiento en el batch actual
    perdida_entrenamiento_batches.append(loss.item())

   # Se guarda el loss de entrenamiento de la época actual
   perdida_entrenamiento.append(np.mean(perdida_entrenamiento_batches)) # Loss promedio de los batches

################################################################################
#---------------  Predicción en conjunto de validación ------------------------#
################################################################################
   model.eval()
   with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases
      outputs = model(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      perdida_validacion_batches.append(loss.item())

   # Guardamos el Loss de validación de la época actual
   perdida_validacion.append(np.mean(perdida_validacion_batches)) # Loss promedio de los batches

   # Guardamos la época
   epochs.append(epoch)

   # Se imprime la pérdida de entrenamiento/validación en la época actual
   print(("Epoch: %d, train loss: %.4f, val loss: %.4f"  %(epoch, perdida_entrenamiento[epoch], perdida_validacion[epoch])))
 #Guardo en lista las pérdidas total para cada modelo.
 total_train_perdida.append(perdida_entrenamiento)
 total_val_perdida.append(perdida_validacion)
 end = time.time()
 print('Finished Training, total time %f seconds' % (end - start))

import matplotlib.pyplot as plt

#Se recorre los 6 modelos, para graficarlos.
for i in range(6):
  #Graficar loss de entrenamiento Y validación
  plt.figure(figsize = (8, 5))
  plt.title('Modelo: '+nombre_modelos[i]+'---> Perdida en Entrenamiento & Validacion')
  plt.xlabel('Numero de epocas')
  plt.ylabel('Perdida')
  plt.plot(epochs, total_train_perdida[i], 'b', label = 'Entrenamiento')
  plt.plot(epochs, total_val_perdida[i], 'r', label = 'Validacion')
  plt.grid()
  plt.legend()

"""##Para evitar sobreajuste en base a las gráficas anteriores, se utilizará un nivel de paciencia (criterio de parada) óptima para cada modelo.

## (a) Cálculo del loss de entrenamiento y el de validación para cada modelo.
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import time

total_train_perdida=[]
total_val_perdida=[]
total_accuracy=[]
#Se crean los modelos.
nombre_modelos=[]
def modelos(numero_modelo):
    if numero_modelo== 1:
        nombre_modelos.append('a')
        return nn.Sequential(
            nn.Linear(64, 10),
            nn.ReLU(),
            nn.Linear(10, 10)
        )
    elif numero_modelo == 2:
        nombre_modelos.append('b')
        return nn.Sequential(
            nn.Linear(64, 40),
            nn.ReLU(),
            nn.Linear(40, 10)
        )
    elif numero_modelo == 3:
        nombre_modelos.append('c')
        return nn.Sequential(
            nn.Linear(64, 10),
            nn.Tanh(),
            nn.Linear(10, 10)
        )
    elif numero_modelo == 4:
        nombre_modelos.append('d')
        return nn.Sequential(
            nn.Linear(64, 40),
            nn.Tanh(),
            nn.Linear(40, 10)
        )
    elif numero_modelo == 5:
        nombre_modelos.append('e')
        return nn.Sequential(
            nn.Linear(64, 10),
            nn.ReLU(),
            nn.Linear(10, 10),
            nn.ReLU(),
            nn.Linear(10, 10)
        )
    elif numero_modelo == 6:
        nombre_modelos.append('f')
        return nn.Sequential(
            nn.Linear(64, 40),
            nn.ReLU(),
            nn.Linear(40, 40),
            nn.ReLU(),
            nn.Linear(40, 10)
        )

lista_modelos=[]
modelo=0
total_epoca=[]
#Se recorre cada modelo.
for n_red in range(1,7):
 print(n_red)
 model = modelos(n_red)
 start = time.time()

 device = torch.device('cuda')
 model = model.to(device)
 criterion = nn.CrossEntropyLoss()
 optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
 lista_modelos.append(model)
 contador = 0
 #Se inicial con un valor gigante.
 best_val_loss = float('inf')
 #Se define distintas paciencias dependiendo del modelo y sus gráficas.
 paciencia=[25,30,20,30,15,35]

 # Se guardan los resultados del loss y epocas que duró el entrenamiento
 perdida_entrenamiento = []
 perdida_validacion = []
 epochs = []
 lista_accuracy=[]

 # Entrenamiento de la red por n epocas
 for epoch in range(1000):

   # Guardar loss de cada batch
   perdida_entrenamiento_batches = []
   perdida_validacion_batches = []

################################################################################
#-------------------------------Entrenamiento ---------------------------------#
################################################################################
   model.train()   #Comienza el entrenamiento.

   # Debemos recorrer cada batch (lote de los datos)
   for i, data in enumerate(dataloader_train, 0):
    # Procesar batch actual
    inputs = data["features"].to(device) # Características
    labels = data["labels"].to(device)   # Clases
    # zero the parameter gradients
    optimizer.zero_grad()
    # forward + backward + optimize
    outputs = model(inputs)           # Predicciones
    loss = criterion(outputs, labels) # Loss de entrenamiento
    loss.backward()                   # Backpropagation
    optimizer.step()

    # Se guarda la pérdida de entrenamiento en el batch actual
    perdida_entrenamiento_batches.append(loss.item())

   # Se guarda la pérdida de entrenamiento de la época actual
   perdida_entrenamiento.append(np.mean(perdida_entrenamiento_batches)) # Loss promedio de los batches

################################################################################
#---------------  Predicción en conjunto de validación ------------------------#
################################################################################
   model.eval()
   correct_predictions = 0.0
   with torch.no_grad():
    # Iteramos dataloader_val para evaluar el modelo en los datos de validación
    for i, data in enumerate(dataloader_val, 0):
      # Procesar batch actual
      inputs = data["features"].to(device) # Características
      labels = data["labels"].to(device)   # Clases
      outputs = model(inputs)              # Obtenemos predicciones

      # Guardamos la pérdida de validación en el batch actual
      loss = criterion(outputs, labels)
      perdida_validacion_batches.append(loss.item())
      _, predicted = torch.max(outputs, 1)
      correct_predictions += (predicted == labels).sum().item()


   # Guardamos el Loss de validación de la época actual
   perdida_validacion.append(np.mean(perdida_validacion_batches)) # Loss promedio de los batches
   validacion_accuracy = correct_predictions / len(dataloader_val.dataset)
   lista_accuracy.append(validacion_accuracy)
   # Guardamos la época
   epochs.append(epoch)

   # Se imprime la pérdida de entrenamiento/validación en la época actual
   print(("Epoch: %d, Perdida entrenamiento: %.4f, Perdida validacion: %.4f, acuraccy: %.4f"  %(epoch, perdida_entrenamiento[epoch], perdida_validacion[epoch],lista_accuracy[epoch])))
   #Se evalúa si la última pérdida de validación sea menor al valor gigante, si se cumple, ese valor de la pérdida se pasa a la variable y no se incrementa en un contador.
   if perdida_validacion[-1] < best_val_loss:
    best_val_loss = perdida_validacion[-1]
    contador = 0  # Reinicia el contador
   else:
    contador+= 1  # Incrementa el contador

    if contador >= paciencia[n_red-1]:
       print(f'Parada temprana de la época {epoch}')
       break  # Se detiene el entrenamiento

 #Se almacenan las pérdidas y la precisión de cada modelo.
 total_train_perdida.append(perdida_entrenamiento)
 total_val_perdida.append(perdida_validacion)
 total_accuracy.append(lista_accuracy[-1])
 total_epoca.append(epochs)
 modelo+=1
 end = time.time()
 print('Finished Training, total time %f seconds' % (end - start))

"""## (b) Grafica del loss de entrenamiento y el de validación en función del tiempo (Época)."""

import matplotlib.pyplot as plt
#Se recorre los 6 modelos, para graficarlos.
for i in range(6):
  #Graficar loss de entrenamiento Y validación
  plt.figure(figsize = (8, 5))
  plt.title('Modelo: '+nombre_modelos[i]+'---> Perdida en Entrenamiento & Validacion')
  plt.xlabel('Numero de epocas')
  plt.ylabel('Perdida')
  plt.plot(total_epoca[i], total_train_perdida[i], 'b', label = 'Entrenamiento')
  plt.plot(total_epoca[i], total_val_perdida[i], 'r', label = 'Validacion')
  plt.grid()
  plt.legend()

"""## (c) Matriz de confusión normalizada y accuracy normalizado, usando el conjunto de entrenamiento."""

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, accuracy_score
import seaborn as sns

#Se crea una función para evaluar un modelo.
def evaluate_model(model, dataloader, device, classes):
    model.eval()
    predicted_labels = []
    true_labels = []

    with torch.no_grad():
        for data in dataloader:
            inputs = data["features"].to(device)
            labels = data["labels"].to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            predicted_labels.extend(predicted.cpu().numpy())
            true_labels.extend(labels.cpu().numpy())

    cm = confusion_matrix(true_labels, predicted_labels, normalize='true')
    accuracy = accuracy_score(true_labels, predicted_labels)

    return cm, accuracy

# Se inicializa las listas para las matrices de confusión y el accuracy por modelo.
model_confusion_matrices = []
model_accuracies = []
#Se define una lista números que representan la cantidad de clases.
classes=[0,1,2,3,4,5,6,7,8,9]
for model in lista_modelos:
    model_cm, model_acc = evaluate_model(model, dataloader_train, device, classes)
    model_confusion_matrices.append(model_cm)
    model_accuracies.append(model_acc)

#Se crea una figura por cada modelo.
for i, model in enumerate(lista_modelos):
    #Se crea una figura para la matriz de confusión del modelo.
    fig, ax = plt.subplots(figsize=(8, 6))

    #Se crea la matriz de confusión.
    model_accuracy_text = f'Accuracy: {model_accuracies[i] * 100:.2f}%'  #Se muestra en pantalla el accuracy.
    sns.heatmap(model_confusion_matrices[i], annot=True, fmt='.2f', cmap='Greens', cbar=True, square=True, ax=ax)
    #Se crea un título.
    ax.set_title(f"Matriz de Confusión de Entrenamiento (Modelo: {nombre_modelos[i]}) --> "+model_accuracy_text)
    ax.set_xlabel('Clase Predicha')  #Se nombra el eje x.
    ax.set_ylabel('Clase Real') #Se nombra el eje y.
    ax.set_xticklabels(classes, fontsize=10)
    ax.set_yticklabels(classes, rotation=0, fontsize=10)

    #Se Configura las etiquetas de clase
    tick_marks = np.arange(len(classes))
    ax.set_xticks(tick_marks)
    ax.set_yticks(tick_marks)
    ax.set_xticklabels(classes)
    ax.set_yticklabels(classes, rotation=0)

    #Se muestra la figura en pantalla.
    plt.show()

"""## (d) Matriz de confusión normalizada y accuracy normalizado, usando el conjunto de validación.

"""

# Inicializa listas para las matrices de confusión y accuracy por modelo en validación
val_model_confusion_matrices = []
val_model_accuracies = []

#Se recorre cada modelo.
for model in lista_modelos:
    #Se llama a la función de evaluación
    val_model_cm, val_model_acc = evaluate_model(model, dataloader_val, device, classes)
    val_model_confusion_matrices.append(val_model_cm)
    val_model_accuracies.append(val_model_acc)

#Se crea una figura por cada modelo en validación
for i, model in enumerate(lista_modelos):
    #Se crea una figura para la matriz de confusión del modelo en validación
    fig, ax = plt.subplots(figsize=(8, 6))

    #Se crea la matriz de confusión en validación
    val_model_accuracy_text = f'Accuracy: {val_model_accuracies[i] * 100:.2f}%'
    sns.heatmap(val_model_confusion_matrices[i], annot=True, fmt='.2f', cmap='Reds', cbar=True, square=True, ax=ax)
    #Se crea un título.
    ax.set_title(f"Matriz de Confusión de Validación (Modelo: {nombre_modelos[i]}) --> "+val_model_accuracy_text)
    ax.set_xlabel('Clase Predicha') #Se nombra el eje x.
    ax.set_ylabel('Clase Real') #Se nombra el eje y.
    ax.set_xticklabels(classes, fontsize=10)
    ax.set_yticklabels(classes, rotation=0, fontsize=10)

    #Se configura las etiquetas de clase
    tick_marks = np.arange(len(classes))
    ax.set_xticks(tick_marks)
    ax.set_yticks(tick_marks)
    ax.set_xticklabels(classes)
    ax.set_yticklabels(classes, rotation=0)

    #Se muestra la figura.
    plt.show()

"""## Mejor accuracy en validación."""

#Teniendo los accuracy de cada modelo.
#Se calcula el máximo de esa lista.
maximo=max(total_accuracy)
#Se determina la posición del máximo.
pos_max=total_accuracy.index(maximo)
#Se imprime los datos del mejor modelo.
print("El mejor modelo es:", nombre_modelos[pos_max], lista_modelos[pos_max])

for i in range(len(total_accuracy)):
   print(total_accuracy[i],"---> Modelo: ", i+1)

"""##Matriz de confusión normalizada y el accuracy normalizado, para la mejor red encontrada en validación, usando el conjunto de prueba.

"""

import torch
from sklearn.metrics import confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

#Se crea el modelo con la misma arquitectura que usaste durante el entrenamiento
best_model=lista_modelos[pos_max]

print("----- El mejor modelo es: ",nombre_modelos[pos_max],"-----------------")
print(best_model)

device = torch.device('cuda')
best_model = best_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

#Se evalua el modelo en el conjunto de prueba
best_model.eval()
test_correct = 0
test_total = 0
test_preds = []
test_labels = []


with torch.no_grad():
    for data in dataloader_test:
        inputs = data["features"].to(device)
        labels = data["labels"].to(device)
        outputs = best_model(inputs)
        _, predicted = torch.max(outputs, 1)
        test_preds.extend(predicted.cpu().numpy())
        test_labels.extend(labels.cpu().numpy())
        test_total += labels.size(0)
        test_correct += (predicted == labels).sum().item()

#Se calcula el accuracy normalizado
test_accuracy = f"{accuracy_score(test_labels, test_preds):.2f}"

#Se calcula la matriz de confusión normalizada
confusion = confusion_matrix(test_labels, test_preds, normalize='true')

#Se visualiza la matriz de confusión normalizada
sns.heatmap(confusion, annot=True, fmt='.2f', cmap='Blues', cbar=True)
plt.title('Matriz de Confusión Normalizada en el Conjunto de Prueba (modelo: '+nombre_modelos[pos_max]+') ' +"Acurracy --> "+str(test_accuracy))
plt.xlabel('Predicciones')
plt.ylabel('Etiquetas Verdaderas')
plt.show()